{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data has been gathered from https://pubs.acs.org/doi/suppl/10.1021/ci9901338/suppl_file/ci9901338_s.pdf, with the SMILEs already attached.\n",
    "\n",
    "I have already edited some of the files to make it cleaner to load. This involved the following:\n",
    "    1. Replacing any tabs with spaces, replacing double spaces with a single space.\n",
    "    2. Combining train.smi and test1.smi into a single dataset.\n",
    "    3. Keeping only the CAS_Number, Name, Log S and Smiles columns.\n",
    "    4. Saving the data as: alldata.csv and test2.csv\n",
    "    \n",
    "If you wish, you may do this for yourself, by downloading the raw files from here: http://cheminformatics.org/datasets/huuskonen/index.html\n",
    "\n",
    "Otherwise, you are welcome to use the .csv files generated for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/alldata.csv\", index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of data entries\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper, they have 1297 compounds, whilst we have 1291 here. \n",
    "\n",
    "Why is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#think, then double click on the markdown cell below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"white\">\n",
    "<i> It is likely that we have less due to the SMILEs strings - if they were not able to be parsed by the data owner, they were excluded from the dataset.</i></font>\n",
    "\n",
    "Let's do a check on a molecule to see if we have accurate data.\n",
    "\n",
    "We can use pandas directly to do this:\n",
    "\n",
    "    data[data[\"Column\"] == \"String\"]] \n",
    "    \n",
    "Replace 'Column' and 'String' with a molecule of your choice and see if you can find it in the raw data [table](https://pubs.acs.org/doi/suppl/10.1021/ci9901338/suppl_file/ci9901338_s.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"Name\"]==\"acetamide\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with Smiles strings as input to our modelling work, so we need to make sure these are unique.\n",
    " \n",
    "You can use value_counts() on a column to find the number of matches to each unique value.\n",
    "e.g.\n",
    "\n",
    "    data[\"Name\"].value_counts()\n",
    "    \n",
    "The output is generated so that values with the highest counts are listed first.\n",
    "    \n",
    "Do this for the Smiles column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify to only look at those that have a count > 1.\n",
    "Don't forget to save your value_counts() as a variable first.\n",
    "\n",
    "    counts[counts > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#work here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the top example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"Smiles\"]==None] # Replace None with the relevant smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both endrin and dieldrin have the same chemical formula: C12H8Cl6O\n",
    "\n",
    "We can draw the molecules to see how RDKit visualises the SMILES representation - We'll look more at this in another notebook.\n",
    "\n",
    "To do this we need to do a few steps first:\n",
    "    1. Chem.MolFromSmiles(smiles)\n",
    "    2. Draw.MolToImage(mol)\n",
    "\n",
    "Take a look at the rdkit documentation for more information on these functions http://www.rdkit.org/Python_Docs/rdkit.Chem.rdmolfiles-module.html\n",
    "    \n",
    "Step 1 takes the smiles string as an argument, and converts it into an RDKit molecule type, so that we can perform further processing using rdkit features.\n",
    "Step 2 takes the mol as an argument, and constructs an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = \"ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl\"\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "Draw.MolToImage(mol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An issue with canonical smiles strings is that tautomers of the same molecule will typically be represented by the same SMILES\n",
    "string. It is therefore often better to use Inchis which can be non-standardised, and are able to represent tautomers.\n",
    "\n",
    "However, as we have no other tautomer information, we will stick with SMILEs.\n",
    "\n",
    "This means that if this is used as input, even though for different tautomers, the descriptors generated will be the same.\n",
    "We will have repeated data, which can cause a problem if one version of the repeat is in the test, and another in the training! \n",
    "\n",
    "If endrin, with a Log S of -6.18 is present in the training set, and dieldrin is present in the test set with a Log S of -6.29, we can always expect dieldrin to have **at least** an error of -0.11 (not considering training error).\n",
    "\n",
    "What should you do? \n",
    "1. Keep all?\n",
    "2. Remove all?\n",
    "3. Keep one?\n",
    "    - Which?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My preference here would be to try to find a way to represent these molecules so that they can become different entities, and then to make sure they end up in the same training/test set. \n",
    "However, due to limitations of the data, we'll just remove them.\n",
    "\n",
    "How would you save the indexes of this 'counts' dataframe as list?\n",
    "Remember to only save those that have a value_counts() > 1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_mols = counts[counts > 1].index.tolist()\n",
    "print(multiple_mols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a quick one liner for excluding all of these from the dataframe.\n",
    "\n",
    "You've already seen:\n",
    "\n",
    "       data[data[\"Name\"] == \"X\"]\n",
    "       \n",
    "We can check for presence in a list according to:\n",
    "\n",
    "        data[data[\"Name\"].isin(X)]\n",
    "            \n",
    "Where X is your list variable.\n",
    "\n",
    "How would you change this line, so it becomes \n",
    "\n",
    "    '\"Name\" is not in list X'?\n",
    "    \n",
    "Hint:<br><font size=5>~</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data = data[None] #Replace None with the code.\n",
    "\n",
    "#We then need to reset the index, so we can avoid copy errors\n",
    "unique_data.reset_index(drop=True,inplace=True)\n",
    "unique_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally need to check that all our data has a Log S value, as this is what we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.all(unique_data[\"Log S\"].isnull())==False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 'data sets' paragraph:\n",
    "    \n",
    "<blockquote>A set of 1297 organic compounds was extracted from these databases and was divided into a training set of 884 compounds and a randomly chosen test set of 413 compounds.</blockquote>\n",
    "\n",
    "You can use sklearn's train_test_split function for this! [Wiki here](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) \n",
    "\n",
    "Have a look at the wiki, and try and split the unique_data into training, and 413 'test' molecules. Don't forget, due to SMILES, we have slightly fewer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(unique_data, test_size=413) #replace None with the correct code\n",
    "\n",
    "#save these as the correct csv files.\n",
    "train.to_csv(\"../train.csv\")\n",
    "test.to_csv(\"../test1.csv\")\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use a handy pandas function to get some statistics.\n",
    "\n",
    "    data.describe()\n",
    "\n",
    "    data[\"Name\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does our means, minimums, maximums and standard deviations compare to those in the paper?\n",
    "\n",
    "<blockquote>The Log S values of the training set ranged from -11.62 to +1.58 with a mean of -2.70 and standard deviation of 2.01. For the testing set, the smallest log S value was -10.41 and the largest +1.13. The mean and standard deviation were -2.77 and 2.07, respectively. </blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could compare our train and test data in a box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to combine into a list so we can plot them\n",
    "data = [train[\"Log S\"],test[\"Log S\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "\n",
    "# Create an axes instance\n",
    "ax = fig.add_subplot(111)\n",
    "ax.boxplot(data)\n",
    "ax.set_ylabel(\"Log S\")\n",
    "ax.set_xticklabels([\"Train\",\"Test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the training data look to be representative of the test data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about the second test set?\n",
    "\n",
    "Do the plot again, but also with the Log S data from test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = pd.read_csv(\"../data/test2.csv\", index_col=0)\n",
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
